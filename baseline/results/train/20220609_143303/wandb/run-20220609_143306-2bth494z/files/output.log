
Train 0/200
Traceback (most recent call last):
  File "D:\film\pytorch\baseline\train.py", line 140, in <module>
    logger.info(f"--Train {epoch_index}/{n_epochs}")
  File "D:\film\pytorch\baseline\modules\trainer.py", line 123, in train
    loss.backward()
  File "C:\Users\rudwn\anaconda3\envs\deeplearning\lib\site-packages\torch\_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\Users\rudwn\anaconda3\envs\deeplearning\lib\site-packages\torch\autograd\__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "C:\Users\rudwn\anaconda3\envs\deeplearning\lib\site-packages\wandb\wandb_torch.py", line 264, in <lambda>
    handle = var.register_hook(lambda grad: _callback(grad, log_track))
KeyboardInterrupt